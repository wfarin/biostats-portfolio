---
title: "Classification of blood cells with CNN"
---

# **Objectives**

::: {style="text-align: justify;"}
The goal of this project is to identify different types of blood cells using computer vision algorithms. The density and relative abundance of blood cells in a smear are crucial for diagnosing many pathologies, such as leukemia, which relies on the lymphocyte ratio. The identification of abnormal leukocytes in diseases like leukemia could complement this first step.

Developing a tool capable of analyzing cells from blood smears could not only facilitate the diagnosis of certain pathologies but also be applied in a research context.
:::

# **Pre-processing and Feature Engineering**

::: {style="text-align: justify;"}
One corrupted image in the Munich dataset was removed. The images were converted to PNG format in order to use Keras’ `image_dataset_from_directory` method, which enables dynamic image loading. In addition, PNG images are approximately ten times smaller than TIFF images.

Furthermore, an outlier detection step was planned based on two features: brightness (mean gray level) and contrast (standard deviation of gray levels) for each image (ScienceDirect Topics, *Image Contrast*). An image is considered an outlier if its brightness deviates by more than two standard deviations from the global mean brightness of the dataset. The same principle is applied to contrast: any image whose standard deviation deviates by more than two standard deviations is flagged as an outlier.
:::

# **Segmentation with Masks**

::: {style="text-align: justify;"}
In the context of cell image classification, one of the major challenges is to direct the model’s attention toward the truly relevant regions — the cells themselves — rather than background elements (artifacts, noise, out-of-focus cells, etc.). Indeed, blood smear images often contain parasitic information such as lighting variations, stains, blurry areas, or multiple partially visible cells. These factors can mislead the classifier, causing it to learn non-discriminative or even detrimental features.

To address this issue, a preliminary segmentation step was introduced. This step relies on a U-Net–based model, an architecture widely used in biomedical image segmentation. U-Net is a convolutional neural network with a U-shaped design, composed of an encoder (extracting global image features) and a symmetric decoder (reconstructing the segmentation map at the original resolution). Skip connections between encoder and decoder layers preserve fine-grained spatial details during reconstruction.
:::

# **Final Classification Model Using Transfer Learning**

::: {style="text-align: justify;"}
The final CNN model incorporates the input masks generated during the segmentation step, combined with transfer learning on ResNet50. We designed an architecture in which the network receives the masked image and extracts features through the pre-trained convolutional layers. This approach significantly improved performance compared to a simple CNN, by directing the model’s focus toward the truly relevant regions of the image using the masks.
:::

# **Training Strategy for the Full Model**

::: {style="text-align: justify;"}
We chose the ResNet50 model with progressive fine-tuning, as it offered the best trade-off between accuracy, training stability, and computational time. The model was trained in several phases: initialization, partial unfreezing, and full unfreezing. It was compiled using the `sparse_categorical_crossentropy` loss function, appropriate for a multi-class classification task.

To address class imbalance, as mentioned earlier, two complementary approaches were implemented:

-   **Data augmentation:** There are three minority classes (debris, immature monocytes, and erythroids) with 10, 17, and 50 images in the training set after the split, respectively. These images were artificially augmented using simple random rotations (25 times per image), without modifying zoom, translation, or contrast. After augmentation, there are therefore 260 (250 + 10) debris images, 442 (425 + 17) immature monocyte images, and 1300 (1250 + 50) erythroid images.

-   **Class weights:** Differentiated weights were incorporated into the loss function to compensate for the imbalance, ranging from 0.3 to 8.6. It is important to avoid excessively extreme weights to maintain a moderate adjustment.
:::

# **Interpretation of the Final Convolutional Layer**

::: {style="text-align: justify;"}
The figure below highlights the regions of the image that contributed most to the prediction. Here, we observe that the model correctly focuses on the central area containing the granular nucleus characteristic of basophils, which reinforces confidence in the automatic classification. This demonstrates the importance of masks in cell classification, by excluding non-relevant regions that could otherwise interfere with the learning of meaningful and specific patterns.
:::

# **Performance Evaluation**

::: {style="text-align: justify;"}
The confusion matrix on the test set demonstrates very good performance on previously unseen data. The accuracy on the test set is 0.94.
:::

<https://github.com/wfarin/mars25_bds_blood_cells>
